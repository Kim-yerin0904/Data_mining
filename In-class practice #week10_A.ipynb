{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb3df78",
   "metadata": {},
   "source": [
    "### Decision Tree(결정트리) :\n",
    "데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리 기반의 분류 규칙을 만드는 알고리즘입니다.\n",
    "(조금 더 쉽게 하자면 if else를 자동으로 찾아내 예측을 위한 규칙을 만드는 알고리즘입니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa352f",
   "metadata": {},
   "source": [
    "### Decision Tree의 구조\n",
    "- 루트노드(Root Node) : 시작점\n",
    "- 리프노드(Leaf Node) : 결정된 클래스 값\n",
    "- 규칙노드/내부노드(Decision Node / Internal Node) : 데이터세트의 피처가 결합해 만들어진 분류를 위한 규칙조건"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4af2d",
   "metadata": {},
   "source": [
    "* 하지만 Decision Tree에서 많은 규칙이 있다는 것은 분류 방식이 복잡해진다는 것이고 이는 과적합(Overfitting)으로 이어지기 쉽습니다.\n",
    "\n",
    "(트리의 깊이(depth)가 깊어질수록 결정트리는 과적합되기 쉬워 예측 성능이 저하될 수 있습니다.)\n",
    "\n",
    "\n",
    "* 가능한 적은 규칙노드로 높은 성능을 가지려면 데이터 분류를 할 때 최대한 많은 데이터 세트가 해당 분류에 속할 수 있도록 규칙 노드의 규칙이 정해져야 합니다.\n",
    "\n",
    "* 이를 위해 최대한 균일한 데이터 세트가 구성되도록 분할(Split)하는 것이 필요합니다.(분할된 데이터가 특정 속성을 잘 나타내야 한다는 것입니다.)\n",
    "\n",
    "* 규칙 노드는 정보균일도가 높은 데이터 세트로 쪼개지도록 조건을 찾아 서브 데이터 세트를 만들고, 이 서브 데이터에서 이런 작업을 반복하며 최종 클래스를 예측하게 됩니다.\n",
    "\n",
    "* 사이킷런에서는 기본적으로 지니계수를 이용하여 데이터를 분할합니다.\n",
    "\n",
    "※ 지니계수 : 경제학에서 불평등지수를 나타낼 때 사용하는 것으로 0일 때 완전 평등, 1일 때 완전 불평등을 의미합니다.\n",
    "\n",
    "* 머신러닝에서는 데이터가 다양한 값을 가질수록 평등하며 특정 값으로 쏠릴 때 불평등한 값이 됩니다.\n",
    "* 즉, 다양성이 낮을수록 균일도가 높다는 의미로 1로 갈수록 균일도가 높아 지니계수가 높은 속성을 기준으로 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b98d5d1",
   "metadata": {},
   "source": [
    "### 파라미터 \n",
    "\n",
    "- criterion \n",
    " > - 분할 품질을 측정하는 기능 (default : gini)\n",
    "\n",
    "- splitter\n",
    " > - 각 노드에서 분할을 선택하는 데 사용되는 전략 (default : best)\n",
    "\n",
    "- min_weight_fraction_leaf\n",
    " > - min_sample_leaf와 같지만 가중치가 부여된 샘플 수에서의 비율\n",
    "\n",
    "- min_samples_split\n",
    " > - 노드를 분할하기 위한 최소한의 샘플 데이터수 → 과적합을 제어하는데 사용\n",
    " > - Default = 2 → 작게 설정할 수록 분할 노드가 많아져 과적합 가능성 증가\n",
    " \n",
    "- min_samples_leaf\n",
    " > - 리프노드가 되기 위해 필요한 최소한의 샘플 데이터수\n",
    " > - min_samples_split과 함께 과적합 제어 용도\n",
    " > - 불균형 데이터의 경우 특정 클래스의 데이터가 극도로 작을 수 있으므로 작게 설정 필요\n",
    " \n",
    "- max_features\n",
    " > - 최적의 분할을 위해 고려할 최대 feature 개수\n",
    " > - Default = None → 데이터 세트의 모든 피처를 사용\n",
    " > - int형으로 지정 →피처 갯수 / float형으로 지정 →비중\n",
    " > - sqrt 또는 auto : 전체 피처 중 √(피처개수) 만큼 선정\n",
    " > - log : 전체 피처 중 log2(전체 피처 개수) 만큼 선정\n",
    " \n",
    "- max_depth\n",
    " > - 트리의 최대 깊이\n",
    " > - default = None\n",
    " > → 완벽하게 클래스 값이 결정될 때 까지 분할\n",
    "또는 데이터 개수가 min_samples_split보다 작아질 때까지 분할\n",
    " > - 깊이가 깊어지면 과적합될 수 있으므로 적절히 제어 필요\n",
    " \n",
    "- max_leaf_nodes\n",
    " > - 리프 노드의 최대 개수\n",
    " \n",
    "- random_state \n",
    " > - 난수 seed 설정\n",
    " \n",
    "- max_leaf_nodes \n",
    " > - 리프 노드의 최대수\n",
    "\n",
    "- min_impurity_decrease \n",
    " >  - 최소 불순도\n",
    "\n",
    "- min_impurity_split \n",
    " > - 나무 성장을 멈추기 위한 임계치\n",
    "\n",
    "- class_weight \n",
    " > - 클래스 가중치\n",
    "\n",
    "- presort \n",
    " > - 데이터 정렬 필요 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f4a0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
